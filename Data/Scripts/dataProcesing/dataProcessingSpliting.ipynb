{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12990 entries, 0 to 12989\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   File Start Date          12990 non-null  object \n",
      " 1   File End Date            12990 non-null  object \n",
      " 2   File Start Time          12990 non-null  object \n",
      " 3   File End Time            12990 non-null  object \n",
      " 4   File Duration            12990 non-null  object \n",
      " 5   Hectometer Head          12990 non-null  float64\n",
      " 6   Hectometer Tail          12990 non-null  float64\n",
      " 7   Route Letter             12990 non-null  object \n",
      " 8   Route Number             12990 non-null  int64  \n",
      " 9   Route Description        12990 non-null  object \n",
      " 10  Hectometering Direction  12990 non-null  object \n",
      " 11  Trajectory From          12990 non-null  object \n",
      " 12  Trajectory To            12990 non-null  object \n",
      " 13  Route                    12990 non-null  object \n",
      "dtypes: float64(2), int64(1), object(11)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"../../../Notebooks/Timo-Eindhoven-Arnhem.csv\"\n",
    "file_path_Eindhoven_Arhem = \"../../../Notebooks/Timo-Eindhoven-Arnhem.csv\"\n",
    "file_path_Eindhoven_DenBosch = \"../../../Notebooks/Timo-Eindhoven-DenBosch.csv\"\n",
    "file_path_Maarheeze_Eindhoven = \"../../../Notebooks/Timo-Maarheeze-Eindhoven.csv\"\n",
    "\n",
    "df_Eindhoven_Arhem = pd.read_csv(file_path_Eindhoven_Arhem)\n",
    "df_Eindhoven_DenBosch = pd.read_csv(file_path_Eindhoven_DenBosch)\n",
    "df_Maarheeze_Eindhoven = pd.read_csv(file_path_Maarheeze_Eindhoven)\n",
    "\n",
    "df_Maarheeze_Arhem = pd.concat([df_Maarheeze_Eindhoven, df_Eindhoven_Arhem], ignore_index=True)\n",
    "df_Maarheeze_DenBosch = pd.concat([df_Maarheeze_Eindhoven, df_Eindhoven_DenBosch], ignore_index= True)\n",
    "\n",
    "df = df_Maarheeze_Arhem\n",
    "ndw_df = pd.read_pickle(\"../../../Notebooks/DONE_24h_intensity-speed-Maarheeze-to-Arnhem_01-12-22_30-11-23.pkl\")\n",
    "\n",
    "# df = df_Maarheeze_DenBosch\n",
    "# ndw_df = pd.read_pickle(\"../../../Notebooks/DONE_24h_intensity-speed-Maarheeze-to-sHertogenbosch_01-12-22_30-11-23\")\n",
    "\n",
    "# List of columns to keep\n",
    "columns_to_keep = [\n",
    "    \"File Start Date\", \"File End Date\", \"File Start Time\", \"File End Time\", \n",
    "    \"File Duration\", \"Hectometer Head\", \"Hectometer Tail\", \"Route Letter\", \n",
    "    \"Route Number\", \"Route Description\", \"Hectometering Direction\", \"Trajectory From\", \"Trajectory To\", \"Route\"\n",
    "]\n",
    "\n",
    "# Drop all other columns except the ones listed above\n",
    "df_filtered = df[columns_to_keep]\n",
    "\n",
    "# Display the first few rows of the filtered dataframe\n",
    "df_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12990 entries, 0 to 12989\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   File Start Date           12990 non-null  object \n",
      " 1   File End Date             12990 non-null  object \n",
      " 2   File Start Time           12990 non-null  object \n",
      " 3   File End Time             12990 non-null  object \n",
      " 4   File Duration             12990 non-null  object \n",
      " 5   Hectometer Head           12990 non-null  float64\n",
      " 6   Hectometer Tail           12990 non-null  float64\n",
      " 7   Route Letter              12990 non-null  object \n",
      " 8   Route Number              12990 non-null  int64  \n",
      " 9   Route Description         12990 non-null  object \n",
      " 10  Hectometering Direction   12990 non-null  object \n",
      " 11  Trajectory From           12990 non-null  object \n",
      " 12  Trajectory To             12990 non-null  object \n",
      " 13  Route                     12990 non-null  object \n",
      " 14  Different Start-End Hour  12990 non-null  bool   \n",
      "dtypes: bool(1), float64(2), int64(1), object(11)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the filtered DataFrame to avoid SettingWithCopyWarning\n",
    "df_filtered_copy = df_filtered.copy()\n",
    "\n",
    "# Converting time columns to datetime for easier filtering\n",
    "df_filtered_copy['File Start Time'] = pd.to_datetime(df_filtered_copy['File Start Time'], format='%H:%M:%S').dt.time\n",
    "df_filtered_copy['File End Time'] = pd.to_datetime(df_filtered_copy['File End Time'], format='%H:%M:%S').dt.time\n",
    "\n",
    "# Adding a new column to check if the start hour is different from the end hour\n",
    "df_filtered_copy['Different Start-End Hour'] = df_filtered_copy['File Start Time'].apply(lambda x: x.hour) != df_filtered_copy['File End Time'].apply(lambda x: x.hour)\n",
    "\n",
    "df_filtered_copy.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12990 entries, 0 to 12989\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   File Start Date           12990 non-null  object \n",
      " 1   File End Date             12990 non-null  object \n",
      " 2   File Start Time           12990 non-null  object \n",
      " 3   File End Time             12990 non-null  object \n",
      " 4   File Duration             12990 non-null  object \n",
      " 5   Hectometer Head           12990 non-null  float64\n",
      " 6   Hectometer Tail           12990 non-null  float64\n",
      " 7   Route Letter              12990 non-null  object \n",
      " 8   Route Number              12990 non-null  int64  \n",
      " 9   Route Description         12990 non-null  object \n",
      " 10  Hectometering Direction   12990 non-null  object \n",
      " 11  Trajectory From           12990 non-null  object \n",
      " 12  Trajectory To             12990 non-null  object \n",
      " 13  Route                     12990 non-null  object \n",
      " 14  Different Start-End Hour  12990 non-null  bool   \n",
      "dtypes: bool(1), float64(2), int64(1), object(11)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_filtered_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15332 entries, 0 to 12989\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   File Start Date           15332 non-null  object \n",
      " 1   File End Date             15332 non-null  object \n",
      " 2   File Start Time           15332 non-null  object \n",
      " 3   File End Time             15332 non-null  object \n",
      " 4   File Duration             15332 non-null  object \n",
      " 5   Hectometer Head           15332 non-null  float64\n",
      " 6   Hectometer Tail           15332 non-null  float64\n",
      " 7   Route Letter              15332 non-null  object \n",
      " 8   Route Number              15332 non-null  int64  \n",
      " 9   Route Description         15332 non-null  object \n",
      " 10  Hectometering Direction   15332 non-null  object \n",
      " 11  Trajectory From           15332 non-null  object \n",
      " 12  Trajectory To             15332 non-null  object \n",
      " 13  Route                     15332 non-null  object \n",
      " 14  Different Start-End Hour  15332 non-null  bool   \n",
      " 15  Hectometer per Minute     15332 non-null  float64\n",
      "dtypes: bool(1), float64(3), int64(1), object(11)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "def calculate_absolute_hectometer_per_minute(row):\n",
    "    \"\"\"\n",
    "    Calculate the absolute value of hectometers per minute for a given row.\n",
    "    \"\"\"\n",
    "    start_datetime = datetime.strptime(f\"{row['File Start Date']} {row['File Start Time']}\", '%Y-%m-%d %H:%M:%S')\n",
    "    end_datetime = datetime.strptime(f\"{row['File End Date']} {row['File End Time']}\", '%Y-%m-%d %H:%M:%S')\n",
    "    total_minutes = (end_datetime - start_datetime).total_seconds() / 60\n",
    "    hectometer_distance = abs(row['Hectometer Tail'] - row['Hectometer Head'])\n",
    "    return hectometer_distance / total_minutes if total_minutes > 0 else 0\n",
    "\n",
    "def split_rows_with_absolute_hpm(data):\n",
    "    \"\"\"\n",
    "    Split rows based on different hours in 'File Start Time' and 'File End Time'\n",
    "    and also consider different dates. The split will end at XX:59:59. \n",
    "    'Hectometer per Minute' is calculated as an absolute value.\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "    for index, row in data.iterrows():\n",
    "        start_date_str = str(row['File Start Date'])\n",
    "        end_date_str = str(row['File End Date'])\n",
    "        start_time_str = str(row['File Start Time'])\n",
    "        end_time_str = str(row['File End Time'])\n",
    "\n",
    "        start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "        end_date = datetime.strptime(end_date_str, '%Y-%m-%d')\n",
    "        start_time = datetime.strptime(start_time_str, '%H:%M:%S')\n",
    "        end_time = datetime.strptime(end_time_str, '%H:%M:%S')\n",
    "\n",
    "        hpm = calculate_absolute_hectometer_per_minute(row)\n",
    "\n",
    "        start_dt = datetime.combine(start_date, start_time.time())\n",
    "        end_dt = datetime.combine(end_date, end_time.time())\n",
    "\n",
    "        while start_dt < end_dt:\n",
    "            new_row = row.copy()\n",
    "            new_row['File Start Date'] = start_dt.strftime('%Y-%m-%d')\n",
    "            new_row['File Start Time'] = start_dt.strftime('%H:%M:%S')\n",
    "\n",
    "            next_hour = (start_dt.replace(minute=0, second=0, microsecond=0) + timedelta(hours=1)) - timedelta(seconds=1)\n",
    "            segment_end_dt = min(next_hour, end_dt)\n",
    "\n",
    "            new_row['File End Date'] = segment_end_dt.strftime('%Y-%m-%d')\n",
    "            new_row['File End Time'] = segment_end_dt.strftime('%H:%M:%S')\n",
    "\n",
    "            time_span = (segment_end_dt - start_dt).total_seconds() / 60\n",
    "            hectometer_span = time_span * hpm\n",
    "            new_row['Hectometer Tail'] = row['Hectometer Head'] + hectometer_span\n",
    "            new_row['Hectometer per Minute'] = hpm\n",
    "\n",
    "            new_data.append(new_row)\n",
    "\n",
    "            start_dt = segment_end_dt + timedelta(seconds=1)\n",
    "            row['Hectometer Head'] = new_row['Hectometer Tail']\n",
    "\n",
    "    return pd.DataFrame(new_data)\n",
    "\n",
    "# Applying the function with absolute hectometer per minute to the dataset\n",
    "split_data_with_absolute_hpm = split_rows_with_absolute_hpm(df_filtered_copy)  # Testing with a smaller subset\n",
    "\n",
    "data_df = split_data_with_absolute_hpm\n",
    "# Adding sorting by 'File Duration' in descending order at the end of the process\n",
    "\n",
    "\n",
    "data_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Start Date</th>\n",
       "      <th>File End Date</th>\n",
       "      <th>File Start Time</th>\n",
       "      <th>File End Time</th>\n",
       "      <th>File Duration</th>\n",
       "      <th>Hectometer Head</th>\n",
       "      <th>Hectometer Tail</th>\n",
       "      <th>Route Letter</th>\n",
       "      <th>Route Number</th>\n",
       "      <th>Route Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Route</th>\n",
       "      <th>Different Start-End Hour</th>\n",
       "      <th>Hectometer per Minute</th>\n",
       "      <th>start_datetime_full</th>\n",
       "      <th>end_datetime_full</th>\n",
       "      <th>time_difference</th>\n",
       "      <th>time_difference_seconds</th>\n",
       "      <th>time_difference_minutes</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>1900-01-01 07:30:28</td>\n",
       "      <td>1900-01-01 07:59:59</td>\n",
       "      <td>134,617</td>\n",
       "      <td>181.500000</td>\n",
       "      <td>181.960456</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A2</td>\n",
       "      <td>...</td>\n",
       "      <td>M-E</td>\n",
       "      <td>True</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>2000-01-01 07:30:28</td>\n",
       "      <td>2000-01-01 07:59:59</td>\n",
       "      <td>0 days 00:29:31</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>29.516667</td>\n",
       "      <td>07:30:28</td>\n",
       "      <td>07:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>1900-01-01 08:59:59</td>\n",
       "      <td>134,617</td>\n",
       "      <td>181.960456</td>\n",
       "      <td>182.896187</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A2</td>\n",
       "      <td>...</td>\n",
       "      <td>M-E</td>\n",
       "      <td>True</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>2000-01-01 08:00:00</td>\n",
       "      <td>2000-01-01 08:59:59</td>\n",
       "      <td>0 days 00:59:59</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>59.983333</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>08:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>1900-01-01 09:00:00</td>\n",
       "      <td>1900-01-01 09:45:05</td>\n",
       "      <td>134,617</td>\n",
       "      <td>182.896187</td>\n",
       "      <td>183.599480</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A2</td>\n",
       "      <td>...</td>\n",
       "      <td>M-E</td>\n",
       "      <td>True</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>2000-01-01 09:00:00</td>\n",
       "      <td>2000-01-01 09:45:05</td>\n",
       "      <td>0 days 00:45:05</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>45.083333</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>09:45:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>1900-01-01 08:08:30</td>\n",
       "      <td>1900-01-01 08:12:00</td>\n",
       "      <td>3,500</td>\n",
       "      <td>163.200000</td>\n",
       "      <td>165.800000</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A2</td>\n",
       "      <td>...</td>\n",
       "      <td>M-E</td>\n",
       "      <td>False</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>2000-01-01 08:08:30</td>\n",
       "      <td>2000-01-01 08:12:00</td>\n",
       "      <td>0 days 00:03:30</td>\n",
       "      <td>210.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>08:08:30</td>\n",
       "      <td>08:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>1900-01-01 16:29:31</td>\n",
       "      <td>1900-01-01 16:36:03</td>\n",
       "      <td>6,533</td>\n",
       "      <td>164.200000</td>\n",
       "      <td>166.300000</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>A2</td>\n",
       "      <td>...</td>\n",
       "      <td>M-E</td>\n",
       "      <td>False</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>2000-01-01 16:29:31</td>\n",
       "      <td>2000-01-01 16:36:03</td>\n",
       "      <td>0 days 00:06:32</td>\n",
       "      <td>392.0</td>\n",
       "      <td>6.533333</td>\n",
       "      <td>16:29:31</td>\n",
       "      <td>16:36:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  File Start Date File End Date     File Start Time       File End Time  \\\n",
       "0      2023-01-12    2023-01-12 1900-01-01 07:30:28 1900-01-01 07:59:59   \n",
       "0      2023-01-12    2023-01-12 1900-01-01 08:00:00 1900-01-01 08:59:59   \n",
       "0      2023-01-12    2023-01-12 1900-01-01 09:00:00 1900-01-01 09:45:05   \n",
       "1      2023-01-12    2023-01-12 1900-01-01 08:08:30 1900-01-01 08:12:00   \n",
       "2      2023-01-12    2023-01-12 1900-01-01 16:29:31 1900-01-01 16:36:03   \n",
       "\n",
       "  File Duration  Hectometer Head  Hectometer Tail Route Letter  Route Number  \\\n",
       "0       134,617       181.500000       181.960456            A             2   \n",
       "0       134,617       181.960456       182.896187            A             2   \n",
       "0       134,617       182.896187       183.599480            A             2   \n",
       "1         3,500       163.200000       165.800000            A             2   \n",
       "2         6,533       164.200000       166.300000            A             2   \n",
       "\n",
       "  Route Description  ... Route Different Start-End Hour Hectometer per Minute  \\\n",
       "0                A2  ...   M-E                     True              0.015600   \n",
       "0                A2  ...   M-E                     True              0.015600   \n",
       "0                A2  ...   M-E                     True              0.015600   \n",
       "1                A2  ...   M-E                    False              0.742857   \n",
       "2                A2  ...   M-E                    False              0.321429   \n",
       "\n",
       "  start_datetime_full   end_datetime_full  time_difference  \\\n",
       "0 2000-01-01 07:30:28 2000-01-01 07:59:59  0 days 00:29:31   \n",
       "0 2000-01-01 08:00:00 2000-01-01 08:59:59  0 days 00:59:59   \n",
       "0 2000-01-01 09:00:00 2000-01-01 09:45:05  0 days 00:45:05   \n",
       "1 2000-01-01 08:08:30 2000-01-01 08:12:00  0 days 00:03:30   \n",
       "2 2000-01-01 16:29:31 2000-01-01 16:36:03  0 days 00:06:32   \n",
       "\n",
       "  time_difference_seconds time_difference_minutes start_time  end_time  \n",
       "0                  1771.0               29.516667   07:30:28  07:59:59  \n",
       "0                  3599.0               59.983333   08:00:00  08:59:59  \n",
       "0                  2705.0               45.083333   09:00:00  09:45:05  \n",
       "1                   210.0                3.500000   08:08:30  08:12:00  \n",
       "2                   392.0                6.533333   16:29:31  16:36:03  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'File Start Time' and 'File End Time' to datetime\n",
    "data_df['File Start Time'] = pd.to_datetime(data_df['File Start Time'], format='%H:%M:%S')\n",
    "data_df['File End Time'] = pd.to_datetime(data_df['File End Time'], format='%H:%M:%S')\n",
    "\n",
    "# Adding a dummy date to the time fields\n",
    "dummy_date = datetime(2000, 1, 1)  # The date doesn't matter, it's just a placeholder\n",
    "\n",
    "# Convert time to string and concatenate with dummy date\n",
    "data_df['start_datetime_full'] = pd.to_datetime(\n",
    "    dummy_date.strftime('%Y-%m-%d') + ' ' + data_df['File Start Time'].dt.strftime('%H:%M:%S')\n",
    ")\n",
    "data_df['end_datetime_full'] = pd.to_datetime(\n",
    "    dummy_date.strftime('%Y-%m-%d') + ' ' + data_df['File End Time'].dt.strftime('%H:%M:%S')\n",
    ")\n",
    "\n",
    "# Calculate the time difference\n",
    "data_df['time_difference'] = data_df['end_datetime_full'] - data_df['start_datetime_full']\n",
    "\n",
    "# Convert time difference to total seconds\n",
    "data_df['time_difference_seconds'] = data_df['time_difference'].dt.total_seconds()\n",
    "\n",
    "# Convert time difference to total minutes\n",
    "data_df['time_difference_minutes'] = data_df['time_difference_seconds'] / 60\n",
    "\n",
    "# Remove the dummy date, keeping only the time\n",
    "data_df['start_time'] = data_df['start_datetime_full'].dt.time\n",
    "data_df['end_time'] = data_df['end_datetime_full'].dt.time\n",
    "\n",
    "# Display the DataFrame\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('forGPT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 362162 entries, 0 to 362161\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Date         362162 non-null  object \n",
      " 1   Time Period  362154 non-null  object \n",
      " 2   HM Section   362162 non-null  float64\n",
      " 3   Min. per HM  362162 non-null  float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Function to generate time ranges (e.g., 07:00 - 08:00)\n",
    "def generate_time_ranges(start_hour, end_hour):\n",
    "    ranges = []\n",
    "    for hour in range(start_hour, end_hour):\n",
    "        start_time = datetime.strptime(f\"{hour:02d}:00\", \"%H:%M\")\n",
    "        end_time = start_time + timedelta(hours=1)\n",
    "        ranges.append((start_time.time(), end_time.time()))\n",
    "    return ranges\n",
    " \n",
    "# Generate time ranges from 00:00 to 23:00\n",
    "time_ranges = generate_time_ranges(0, 24)\n",
    " \n",
    "# Function to assign a time range to a datetime\n",
    "def assign_time_range(dt, time_ranges):\n",
    "    for start, end in time_ranges:\n",
    "        if start <= dt.time() < end:\n",
    "            return f\"{start.strftime('%H:%M')} - {end.strftime('%H:%M')}\"\n",
    "    return None\n",
    " \n",
    "# Assigning time ranges to each record\n",
    "data_df['Time Period'] = data_df['File Start Time'].apply(lambda dt: assign_time_range(dt, time_ranges))\n",
    "\n",
    "# Calculate the delay per hectometer\n",
    "data_df['HM Difference'] = data_df['Hectometer Tail'] - data_df['Hectometer Head']\n",
    "data_df['Time Difference'] = (data_df['File End Time'] - data_df['File Start Time']).dt.total_seconds() / 60  # in minutes\n",
    "data_df['Min. per HM'] = data_df['Time Difference'] / data_df['HM Difference']\n",
    " \n",
    "# Function to split the data for every 0.1 HM increment\n",
    "def split_hm_sections(row):\n",
    "    hm_start = row['Hectometer Head']\n",
    "    hm_end = row['Hectometer Tail']\n",
    "    hm_sections = []\n",
    " \n",
    "    # Generate 0.1 HM increments within the range\n",
    "    while hm_start < hm_end:\n",
    "        next_hm = min(hm_start + 0.1, hm_end)\n",
    "        hm_sections.append({\n",
    "            'Date': row['File Start Date'],\n",
    "            'Time Period': row['Time Period'],\n",
    "            'HM Section': round(hm_start, 1),\n",
    "            'Min. per HM': row['Min. per HM'] * (next_hm - hm_start)\n",
    "        })\n",
    "        hm_start = next_hm\n",
    " \n",
    "    return hm_sections\n",
    " \n",
    "\n",
    "\n",
    "# Apply the function to each row and create a new DataFrame\n",
    "split_data = pd.DataFrame([item for _, row in data_df.iterrows() for item in split_hm_sections(row)])\n",
    "\n",
    "split_data.info()\n",
    "split_data.to_csv(\"../Merge/Maarheeze_Arhem.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the data by 'Time Period' and 'File Start Date' and summing the 'Time Difference Minutes'\n",
    "grouped_data = data_df.groupby(['Time Period', 'File Start Date'])['time_difference_minutes'].sum().reset_index()\n",
    "\n",
    "#Renaming the column for clarity\n",
    "grouped_data.rename(columns={'time_difference_minutes': 'Total Time Difference (Minutes)'}, inplace=True)\n",
    "\n",
    "grouped_data.to_csv('nonTimeSort.csv', index=False)\n",
    "#grouped_data.info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time Period</th>\n",
       "      <th>HM Section</th>\n",
       "      <th>Min. per HM</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149483</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>06:00 - 07:00</td>\n",
       "      <td>163.9</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>2022-12-01 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149613</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>06:00 - 07:00</td>\n",
       "      <td>165.6</td>\n",
       "      <td>0.130833</td>\n",
       "      <td>2022-12-01 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149614</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>06:00 - 07:00</td>\n",
       "      <td>165.7</td>\n",
       "      <td>0.130833</td>\n",
       "      <td>2022-12-01 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149615</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>06:00 - 07:00</td>\n",
       "      <td>165.8</td>\n",
       "      <td>0.130833</td>\n",
       "      <td>2022-12-01 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149616</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>06:00 - 07:00</td>\n",
       "      <td>165.9</td>\n",
       "      <td>0.130833</td>\n",
       "      <td>2022-12-01 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149375</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>16:00 - 17:00</td>\n",
       "      <td>160.5</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>2022-12-01 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351142</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>16:00 - 17:00</td>\n",
       "      <td>140.4</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>2022-12-01 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351141</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>16:00 - 17:00</td>\n",
       "      <td>140.3</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>2022-12-01 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351140</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>16:00 - 17:00</td>\n",
       "      <td>140.2</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>2022-12-01 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351139</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>16:00 - 17:00</td>\n",
       "      <td>140.1</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>2022-12-01 16:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date    Time Period  HM Section  Min. per HM            Datetime\n",
       "149483  2022-12-01  06:00 - 07:00       163.9     0.123810 2022-12-01 06:00:00\n",
       "149613  2022-12-01  06:00 - 07:00       165.6     0.130833 2022-12-01 06:00:00\n",
       "149614  2022-12-01  06:00 - 07:00       165.7     0.130833 2022-12-01 06:00:00\n",
       "149615  2022-12-01  06:00 - 07:00       165.8     0.130833 2022-12-01 06:00:00\n",
       "149616  2022-12-01  06:00 - 07:00       165.9     0.130833 2022-12-01 06:00:00\n",
       "...            ...            ...         ...          ...                 ...\n",
       "149375  2022-12-01  16:00 - 17:00       160.5     0.500667 2022-12-01 16:00:00\n",
       "351142  2022-12-01  16:00 - 17:00       140.4     0.104167 2022-12-01 16:00:00\n",
       "351141  2022-12-01  16:00 - 17:00       140.3     0.104167 2022-12-01 16:00:00\n",
       "351140  2022-12-01  16:00 - 17:00       140.2     0.104167 2022-12-01 16:00:00\n",
       "351139  2022-12-01  16:00 - 17:00       140.1     0.104167 2022-12-01 16:00:00\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "grouped_data = split_data\n",
    "\n",
    "# Function to convert time period and date into a single datetime object\n",
    "def convert_to_datetime(date_str, time_period):\n",
    "    if time_period is None:\n",
    "        return None  # or some default value e.g., datetime.min\n",
    "    start_hour = int(time_period.split(':')[0])\n",
    "    datetime_str = f\"{date_str} {start_hour:02d}:00\"\n",
    "    return datetime.strptime(datetime_str, '%Y-%m-%d %H:%M')\n",
    "\n",
    "# Applying the function to each row\n",
    "grouped_data['Datetime'] = grouped_data.apply(lambda row: convert_to_datetime(row['Date'], row['Time Period']), axis=1)\n",
    "\n",
    "# Sorting the data by the new datetime column\n",
    "sorted_data = grouped_data.sort_values(by='Datetime')\n",
    "\n",
    "sorted_data.to_csv('TimeSort.csv', index=False)\n",
    "\n",
    "# Displaying the sorted data\n",
    "sorted_data.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create 'date_of_measurement' by extracting the date part and converting it to string\u001b[39;00m\n\u001b[0;32m     17\u001b[0m ndw_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_measurement\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ndw_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_measurement_period\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndw_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHour\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate_of_measurement\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhour_of_day\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\merge.py:883\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m--> 883\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    886\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    887\u001b[0m )\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\merge.py:1133\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1130\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1131\u001b[0m     )\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\merge.py:1105\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_join_indexers\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]]:\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"return the join indexers\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\merge.py:1728\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how)\u001b[0m\n\u001b[0;32m   1718\u001b[0m join_func \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m: libjoin\u001b[38;5;241m.\u001b[39minner_join,\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m: libjoin\u001b[38;5;241m.\u001b[39mleft_outer_join,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1724\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m: libjoin\u001b[38;5;241m.\u001b[39mfull_outer_join,\n\u001b[0;32m   1725\u001b[0m }[how]\n\u001b[0;32m   1727\u001b[0m \u001b[38;5;66;03m# error: Cannot call function of unknown type\u001b[39;00m\n\u001b[1;32m-> 1728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m join_func(lkey, rkey, count, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Taking the first part of the \"Time Period\" and just the hour part\n",
    "sorted_data['Hour'] = sorted_data['Time Period'].str.split('-').str[0].str.strip().str[:2]\n",
    "    \n",
    "# Read the Weather data\n",
    "weather_df = pd.read_csv('../../../Notebooks/Timo-Weather.csv')\n",
    "    \n",
    "# Ensure that 'Hour' in weather and ndw data is a string for proper matching\n",
    "weather_df['Hour'] = weather_df['Hour'].astype(str).str.zfill(2)  # Adding leading zero if needed\n",
    "ndw_df['hour_of_day'] = ndw_df['hour_of_day'].astype(str).str.zfill(2)  # Adding leading zero if needed\n",
    "\n",
    "merged_df = pd.merge(sorted_data, weather_df, how='left', left_on=['Date', 'Hour'], right_on=['Date', 'Hour'])\n",
    "\n",
    "# Convert 'start_measurement_period' to datetime objects\n",
    "ndw_df['start_measurement_period'] = pd.to_datetime(ndw_df['start_measurement_period'])\n",
    "\n",
    "# Create 'date_of_measurement' by extracting the date part and converting it to string\n",
    "ndw_df['date_of_measurement'] = ndw_df['start_measurement_period'].dt.date.astype(str)\n",
    "\n",
    "merged_df = pd.merge(merged_df, ndw_df, how='left', left_on=['Date', 'Hour'], right_on=['date_of_measurement','hour_of_day'])\n",
    "\n",
    "merged_df.head(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
